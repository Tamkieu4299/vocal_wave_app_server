{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf60145-8d19-4a55-a6cf-490844179c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit_webrtc import webrtc_streamer\n",
    "import av\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import mediapipe as mp \n",
    "from keras.models import load_model\n",
    "import webbrowser\n",
    "\n",
    "model  = load_model(\"model.h5\")\n",
    "label = np.load(\"labels.npy\")\n",
    "holistic = mp.solutions.holistic\n",
    "holis = holistic.Holistic()\n",
    "drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92241f5c-ca2c-4ec4-8679-e05213021bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:03:30.613 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "st.header(\"Allow us to access to your camera?\")\n",
    "\n",
    "if \"run\" not in st.session_state:\n",
    "\tst.session_state[\"run\"] = \"true\"\n",
    "\n",
    "try:\n",
    "\temotion = np.load(\"emotion.npy\")[0]\n",
    "except:\n",
    "\temotion=\"\"\n",
    "\n",
    "if not(emotion):\n",
    "\tst.session_state[\"run\"] = \"true\"\n",
    "else:\n",
    "\tst.session_state[\"run\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6edb15-4244-449c-abc2-66a6fde91279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionProcessor:\n",
    "\tdef recv(self, frame):\n",
    "\t\tfrm = frame.to_ndarray(format=\"bgr24\")\n",
    "\n",
    "\t\t##############################\n",
    "\t\tfrm = cv2.flip(frm, 1)\n",
    "\n",
    "\t\tres = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\t\tlst = []\n",
    "\n",
    "\t\tif res.face_landmarks:\n",
    "\t\t\tfor i in res.face_landmarks.landmark:\n",
    "\t\t\t\tlst.append(i.x - res.face_landmarks.landmark[1].x)\n",
    "\t\t\t\tlst.append(i.y - res.face_landmarks.landmark[1].y)\n",
    "\n",
    "\t\t\tif res.left_hand_landmarks:\n",
    "\t\t\t\tfor i in res.left_hand_landmarks.landmark:\n",
    "\t\t\t\t\tlst.append(i.x - res.left_hand_landmarks.landmark[8].x)\n",
    "\t\t\t\t\tlst.append(i.y - res.left_hand_landmarks.landmark[8].y)\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor i in range(42):\n",
    "\t\t\t\t\tlst.append(0.0)\n",
    "\n",
    "\t\t\tif res.right_hand_landmarks:\n",
    "\t\t\t\tfor i in res.right_hand_landmarks.landmark:\n",
    "\t\t\t\t\tlst.append(i.x - res.right_hand_landmarks.landmark[8].x)\n",
    "\t\t\t\t\tlst.append(i.y - res.right_hand_landmarks.landmark[8].y)\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor i in range(42):\n",
    "\t\t\t\t\tlst.append(0.0)\n",
    "\n",
    "\t\t\tlst = np.array(lst).reshape(1,-1)\n",
    "\n",
    "\t\t\tpred = label[np.argmax(model.predict(lst))]\n",
    "\n",
    "\t\t\tprint(pred)\n",
    "\t\t\tcv2.putText(frm, pred, (50,50),cv2.FONT_ITALIC, 1, (255,0,0),2)\n",
    "\n",
    "\t\t\tnp.save(\"emotion.npy\", np.array([pred]))\n",
    "\n",
    "\t\t\t\n",
    "\t\tdrawing.draw_landmarks(frm, res.face_landmarks, holistic.FACEMESH_TESSELATION,\n",
    "\t\t\t\t\t\t\t\tlandmark_drawing_spec=drawing.DrawingSpec(color=(0,0,255), thickness=-1, circle_radius=1),\n",
    "\t\t\t\t\t\t\t\tconnection_drawing_spec=drawing.DrawingSpec(thickness=1))\n",
    "\n",
    "\t\t##############################\n",
    "\n",
    "\t\treturn av.VideoFrame.from_ndarray(frm, format=\"bgr24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06eb9e2d-ae66-4535-837e-a8ed61c5c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_btn = st.button(\"Yes\")\n",
    "no_btn = st.button(\"No\")\n",
    "if yes_btn and st.session_state[\"run\"] != \"false\":\n",
    "\twebrtc_streamer(key=\"key\", desired_playing_state=True,\n",
    "\t\t\t\tvideo_processor_factory=EmotionProcessor)\n",
    "\n",
    "if not(emotion):\n",
    "\tst.warning(\"Please let me capture your emotion first\")\n",
    "\tst.session_state[\"run\"] = \"true\"\n",
    "else:\n",
    "\tnp.save(\"emotion.npy\", np.array([\"\"]))\n",
    "\tst.session_state[\"run\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9386e-46f5-4a64-b722-3326ce55ee5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
